{"format": "torch", "nodes": [{"name": "init_embed_depot", "id": 5503815240, "class_name": "Linear(in_features=2, out_features=128, bias=True)", "parameters": [["weight", [128, 2]], ["bias", [128]]], "output_shape": [[512, 128]], "num_parameters": [256, 128]}, {"name": "init_embed", "id": 5503815296, "class_name": "Linear(in_features=3, out_features=128, bias=True)", "parameters": [["weight", [128, 3]], ["bias", [128]]], "output_shape": [[512, 20, 128]], "num_parameters": [384, 128]}, {"name": "embedder", "id": 5503815352, "class_name": "GraphAttentionEncoder(\n  (layers): Sequential(\n    (0): MultiHeadAttentionLayer(\n      (0): SkipConnection(\n        (module): MultiHeadAttention()\n      )\n      (1): Normalization(\n        (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): SkipConnection(\n        (module): Sequential(\n          (0): Linear(in_features=128, out_features=512, bias=True)\n          (1): ReLU()\n          (2): Linear(in_features=512, out_features=128, bias=True)\n        )\n      )\n      (3): Normalization(\n        (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): MultiHeadAttentionLayer(\n      (0): SkipConnection(\n        (module): MultiHeadAttention()\n      )\n      (1): Normalization(\n        (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): SkipConnection(\n        (module): Sequential(\n          (0): Linear(in_features=128, out_features=512, bias=True)\n          (1): ReLU()\n          (2): Linear(in_features=512, out_features=128, bias=True)\n        )\n      )\n      (3): Normalization(\n        (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (2): MultiHeadAttentionLayer(\n      (0): SkipConnection(\n        (module): MultiHeadAttention()\n      )\n      (1): Normalization(\n        (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): SkipConnection(\n        (module): Sequential(\n          (0): Linear(in_features=128, out_features=512, bias=True)\n          (1): ReLU()\n          (2): Linear(in_features=512, out_features=128, bias=True)\n        )\n      )\n      (3): Normalization(\n        (normalizer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n)", "parameters": [["layers.0.0.module.W_query", [8, 128, 16]], ["layers.0.0.module.W_key", [8, 128, 16]], ["layers.0.0.module.W_val", [8, 128, 16]], ["layers.0.0.module.W_out", [8, 16, 128]], ["layers.0.1.normalizer.weight", [128]], ["layers.0.1.normalizer.bias", [128]], ["layers.0.2.module.0.weight", [512, 128]], ["layers.0.2.module.0.bias", [512]], ["layers.0.2.module.2.weight", [128, 512]], ["layers.0.2.module.2.bias", [128]], ["layers.0.3.normalizer.weight", [128]], ["layers.0.3.normalizer.bias", [128]], ["layers.1.0.module.W_query", [8, 128, 16]], ["layers.1.0.module.W_key", [8, 128, 16]], ["layers.1.0.module.W_val", [8, 128, 16]], ["layers.1.0.module.W_out", [8, 16, 128]], ["layers.1.1.normalizer.weight", [128]], ["layers.1.1.normalizer.bias", [128]], ["layers.1.2.module.0.weight", [512, 128]], ["layers.1.2.module.0.bias", [512]], ["layers.1.2.module.2.weight", [128, 512]], ["layers.1.2.module.2.bias", [128]], ["layers.1.3.normalizer.weight", [128]], ["layers.1.3.normalizer.bias", [128]], ["layers.2.0.module.W_query", [8, 128, 16]], ["layers.2.0.module.W_key", [8, 128, 16]], ["layers.2.0.module.W_val", [8, 128, 16]], ["layers.2.0.module.W_out", [8, 16, 128]], ["layers.2.1.normalizer.weight", [128]], ["layers.2.1.normalizer.bias", [128]], ["layers.2.2.module.0.weight", [512, 128]], ["layers.2.2.module.0.bias", [512]], ["layers.2.2.module.2.weight", [128, 512]], ["layers.2.2.module.2.bias", [128]], ["layers.2.3.normalizer.weight", [128]], ["layers.2.3.normalizer.bias", [128]]], "output_shape": [[512, 21, 128], [512, 128]], "num_parameters": [16384, 16384, 16384, 16384, 128, 128, 65536, 512, 65536, 128, 128, 128, 16384, 16384, 16384, 16384, 128, 128, 65536, 512, 65536, 128, 128, 128, 16384, 16384, 16384, 16384, 128, 128, 65536, 512, 65536, 128, 128, 128]}, {"name": "project_fixed_context", "id": 5503954056, "class_name": "Linear(in_features=128, out_features=128, bias=False)", "parameters": [["weight", [128, 128]]], "output_shape": [[512, 128]], "num_parameters": [16384]}, {"name": "project_node_embeddings", "id": 5503953832, "class_name": "Linear(in_features=128, out_features=384, bias=False)", "parameters": [["weight", [384, 128]]], "output_shape": [[512, 1, 21, 384]], "num_parameters": [49152]}, {"name": "project_step_context", "id": 5503954112, "class_name": "Linear(in_features=129, out_features=128, bias=False)", "parameters": [["weight", [128, 129]]], "output_shape": [[512, 1, 128]], "num_parameters": [16512]}, {"name": "project_out", "id": 5503954168, "class_name": "Linear(in_features=128, out_features=128, bias=False)", "parameters": [["weight", [128, 128]]], "output_shape": [[512, 1, 1, 128]], "num_parameters": [16384]}], "edges": []}